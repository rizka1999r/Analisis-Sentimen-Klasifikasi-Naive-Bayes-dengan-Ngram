{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fuC639b_pn3x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657667124174,"user_tz":-420,"elapsed":5652,"user":{"displayName":"untuk skirpsi","userId":"08057832302545580320"}},"outputId":"9ef4f84b-5f2b-4b40-b432-43bc7489730d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Sastrawi\n","  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 4.2 MB/s \n","\u001b[?25hInstalling collected packages: Sastrawi\n","Successfully installed Sastrawi-1.0.1\n"]}],"source":["!pip install Sastrawi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwIYW9ZdKh6O"},"outputs":[],"source":["# Import some libraries\n","\n","import pandas as pd\n","pd.options.mode.chained_assignment = None\n","import numpy as np\n","seed = 0\n","np.random.seed(seed)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set(style = 'whitegrid')\n","\n","import nest_asyncio\n","nest_asyncio.apply()\n","\n","import datetime as dt\n","import re\n","import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n","from wordcloud import WordCloud\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from keras.models import Sequential\n","from keras.layers import Embedding, Dense, Dropout, LSTM\n","from keras.callbacks import EarlyStopping\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV\n","from mlxtend.plotting import plot_confusion_matrix\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJGhP3zZ_IFD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657667152339,"user_tz":-420,"elapsed":24943,"user":{"displayName":"untuk skirpsi","userId":"08057832302545580320"}},"outputId":"00c677f7-2653-4fdc-b8c3-91b28216cbda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#access google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nD3j9B7ENtsq"},"outputs":[],"source":["#rename nama kolom\n","df = pd.read_csv('/content/drive/My Drive/dikumpulkan/Invasi_Rusia_file.csv')\n","df.rename({'Unnamed: 0':'no'}, axis=1, inplace = True)\n","df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tF8dF9JR_nc_"},"outputs":[],"source":["# Load data from a CSV file into pandas DataFrame\n","tweets_data = pd.read_csv('/content/drive/My Drive/data/Invasi_Rusia_file.csv')\n","tweets = tweets_data[['created_at','text']]\n","tweets.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hriOqL6uB-3s"},"outputs":[],"source":["# Some functions for preprocessing text\n","\n","# Initializing stemming library\n","factory = StemmerFactory()\n","stemmer = factory.create_stemmer()\n","\n","from urllib.request import urlopen\n","import json\n","\n","def cleaningText(text):#function tahap cleaning\n","    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n","    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n","    text = re.sub(r'RT[\\s]', '', text) # remove RT\n","    text = re.sub(r\"http\\S+\", '', text) # remove link\n","                                        #text = re.sub(r'[0-9]+', '', text) # remove numbers\n","    text = re.sub(r'[^A-Za-z ]+', '', text) #remove all character non alfabet\n","\n","    text = text.replace('\\n', ' ') # replace new line into space\n","    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n","    text = text.strip(' ') # remove characters space from both left and right text\n","    return text\n","\n","def casefoldingText(text): # Converting all the characters in a text into lower case\n","    text = text.lower() \n","    return text\n","\n","def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n","    text = word_tokenize(text)\n","    return text\n","\n","def filteringText(text): # Remove stopwors in a text\n","    listStopwords = set(stopwords.words('indonesian'))\n","    filtered = []\n","    for txt in text:\n","        if txt not in listStopwords:\n","            filtered.append(txt)\n","    text = filtered \n","    return text\n","\n","def stemmingText(text): # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n","    text = [stemmer.stem(word) for word in text]\n","    return text\n","\n","def toSentence(list_words): # Convert list of words into sentence\n","    sentence = ' '.join(word for word in list_words)\n","    return sentence\n","\n","# slang indonesia\n","response_slang = urlopen('https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/master/combined_slang_words.txt')\n","data_slang = json.loads(response_slang.read().decode())\n","def slangWordID(t):\n","    t = \" \".join([data_slang.get(w,w) for w in t.split()])\n","    return t\n","\n","# print(slangWordID(\"ka\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFHK-yGdCVAN"},"outputs":[],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g4I6Qa6HCoAk"},"outputs":[],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VWM6PXMCYqz"},"outputs":[],"source":["# tweets = tweets[:5]\n","\n","# Preprocessing tweets data\n","tweets['text_clean'] = tweets['text'].apply(cleaningText)\n","tweets.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9rCRNlcQe3L"},"outputs":[],"source":["tweets['text_clean'] = tweets['text_clean'].apply(casefoldingText)\n","# tweets.drop(['text'], axis = 1, inplace = True)\n","tweets.head(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJe1SOaSN-9P"},"outputs":[],"source":["tweets['text_preprocessed'] = tweets['text_clean'].apply(tokenizingText)\n","tweets.head(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZIoZh2SffHA"},"outputs":[],"source":["tweets['text_preprocessed'] = tweets['text_preprocessed'].apply(filteringText)\n","tweets.head(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RC84tdhbOIr5"},"outputs":[],"source":["tweets['text_preprocessed'] = tweets['text_preprocessed'].apply(stemmingText)\n","tweets.head(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuOsklDxKmn5"},"outputs":[],"source":["tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SW8IJClION1Q"},"outputs":[],"source":["tweets['text_preprocessed'] = tweets['text_preprocessed'].apply(toSentence)\n","tweets.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xpAAzdcQqmh"},"outputs":[],"source":["tweets['text_preprocessed'] = tweets['text_preprocessed'].apply(slangWordID)\n","\n","# drop duplicates/spams tweets\n","tweets.drop_duplicates(subset = 'text_clean', inplace = True)\n","tweets.head(50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_mb-c1wGMama"},"outputs":[],"source":["# Export to csv file\n","tweets.to_csv(r'/content/drive/My Drive/dikumpulkan/preposecessing.csv', index = False, header = True,index_label=None)\n","\n","tweets\n","\n","# print(tweets['text_clean'][0])\n","# print('\\r')\n","# print(tweets['text_preprocessed'][0])"]}],"metadata":{"colab":{"name":"Prepocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObtzC/P3cAqLt4Z2CsTLlT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}